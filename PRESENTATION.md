# Voice Agent - Kurze Demo-PrÃ¤sentation (2-3 Min)

## Ãœber mich

**Phi Nguyen** Â· Softwareentwickler  
- **Hauptberuflich:** Unternehmen fÃ¼r LogistiksoftwarelÃ¶sungen â€“ optimiere interne Lagerlogistikprozesse (Server, Client, DevOps: TeamCity, GitHub Actions)  
- **Nebenberuflich:** Projekte u. a. Klinikbereich, GroÃŸhandel (Eâ€‘Commerce, Kassenintegrationen), Automatisierungen mit und ohne KI  

---

## 1. Problem

**Das Problem:**
- Meetings, KundengesprÃ¤che, Interviews, **persÃ¶nliche Notizen** â†’ Sprachaufnahmen
- **Mittendrin Notizen manuell aufschreiben** â€“ gleichzeitig zuhÃ¶ren und schreiben
- Aufnahmen bleiben **Rohdaten** â€“ schwer durchsuchbar und nicht geordnet
- MÃ¼hsam in **geordnete Notizen** zu Ã¼berfÃ¼hren
- In vielen Aufnahmen gezielt etwas wiederfinden â†’ manuell durchhÃ¶ren
- Workflow: Aufnahme â†’ Transkription â†’ Strukturierung â†’ Export
- Erfordert **mehrere Tools** und viel **manuellen Aufwand**

**Die LÃ¶sung:**
- Aufnahme â†’ automatische Transkription (Whisper) â†’ KI-Anreicherung (GPT)
- Strukturierte Notizen, Export (PDF, E-Mail, Google Docs)
- RAG-Chat fÃ¼r semantische Suche Ã¼ber alle Aufnahmen

---

## 2. Architektur

```
Frontend (Next.js :3000) â†’ Backend (Express :4000) â†’ PostgreSQL (:5432)
                                    â†“
                              OpenAI (Whisper + GPT)
```

**Pipeline:**
```
Aufnahme â†’ Upload â†’ Transkription (Whisper) â†’ Enrichment (GPT) â†’ Output
```

**Tech-Stack:**
- Frontend: Next.js 14 + Electron + TypeScript
- Backend: Node.js + Express + Knex.js
- Database: PostgreSQL 15 + pgvector (fÃ¼r RAG)
- AI: OpenAI Whisper + GPT-4o-mini

---

## 3. Installation & Start

### Option 1: Desktop-App (Empfohlen)
```bash
# Installer Ã¶ffnen
open "frontend/dist-electron/EverlastAI - Audio Intelligence-1.0.0-arm64.dmg"
# App installieren und starten
```

### Option 2: Docker (Schnellstart)
```bash
git clone <repo> && cd voice-agent
cp .env.example .env  # OPENAI_API_KEY eintragen
docker compose up -d
# â†’ Frontend: http://localhost:3000
```

### Option 3: Lokal
```bash
# Terminal 1: Backend
cd backend && npm i && npm run migrate && npm run dev

# Terminal 2: Frontend
cd frontend && npm i && npm run dev
```

---

## 4. Nutzung - Demo-Ablauf

### Schritt 1: Aufnahme starten
- **Record-Button klicken** oder **Hotkey: `Cmd/Ctrl+Shift+V`**
- Waveform zeigt Live-Audio
- **Demo-Text sprechen:** *"Ich muss morgen um 10 Uhr ein Meeting vorbereiten. Die wichtigsten Punkte sind: Budget-Planung, Team-Update und Q4-Review."*

### Schritt 2: Aufnahme stoppen & verarbeiten
- **`Escape`** oder **Stop-Button**
- **"Aufnahme verarbeiten & transkribieren"** klicken
- Transkription erscheint automatisch (Whisper)

### Schritt 3: KI-Anreicherung
- **"Zusammenfassung erstellen"** â†’ Kurze Zusammenfassung
- **"Action Items"** â†’ To-Dos werden extrahiert
- **"Complete Enrichment"** â†’ VollstÃ¤ndige Notizen mit Struktur
- Alle Enrichments sind editierbar

### Schritt 4: Export & Sharing
- **"Als PDF exportieren"** â†’ Download
- **"Per E-Mail senden"** â†’ E-Mail-Versand
- **"Zu Google Docs"** â†’ Google Docs Integration

### Schritt 5: RAG-Chat (Optional)
- **Chat-Tab** Ã¶ffnen
- Frage: *"Was muss ich morgen vorbereiten?"*
- System findet relevante Aufnahme Ã¼ber semantische Suche

---

## ðŸŽ¯ Zusammenfassung

**Workflow:** Aufnahme â†’ Transkription â†’ Enrichment â†’ Export  
**Besonderheit:** RAG-Chat fÃ¼r semantische Suche Ã¼ber alle Aufnahmen  
**Hotkeys:** `Cmd/Ctrl+Shift+V` (Record), `Escape` (Stop)
